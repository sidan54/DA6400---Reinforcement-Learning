{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DA6400 - Tutorial 2"
      ],
      "metadata": {
        "id": "sX5PxWbbqwNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adil Sidan EP20B003"
      ],
      "metadata": {
        "id": "3x0HjEtFq1ty"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LD5-1Iw8PafI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import NamedTuple\n",
        "from google.colab import output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 0\n",
        "\n",
        "BOARD_COL = 3\n",
        "BOARD_ROW = 3\n",
        "BOARD_SIZE = BOARD_COL * BOARD_ROW\n",
        "\n",
        "\"\"\"\n",
        "Game board and actions are: {q, w, e, a, s, d, z, x, c}\n",
        "\n",
        "q | w | e\n",
        "--|---|--\n",
        "a | s | d\n",
        "--|---|--\n",
        "z | x | c\n",
        "\"\"\"\n",
        "ACTIONS_KEY_MAP = {'q': 0, 'w': 1, 'e': 2,\n",
        "                   'a': 3, 's': 4, 'd': 5,\n",
        "                   'z': 6, 'x': 7, 'c': 8}"
      ],
      "metadata": {
        "id": "I04JDLKvQwPo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "n7lTbDhBy5Of"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### State Definition"
      ],
      "metadata": {
        "id": "UQhLYLOByy-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_state(board, clear_output=False):\n",
        "  if clear_output:\n",
        "    output.clear()\n",
        "  for i in range(BOARD_ROW):\n",
        "    print('-------------')\n",
        "    out = '| '\n",
        "    for j in range(BOARD_COL):\n",
        "      if board[i, j] == 1:\n",
        "          token = 'x'\n",
        "      elif board[i, j] == -1:\n",
        "          token = 'o'\n",
        "      else:\n",
        "          token = ' '  # empty position\n",
        "      out += token + ' | '\n",
        "    print(out)\n",
        "  print('-------------')\n",
        "\n",
        "\n",
        "class State:\n",
        "  def __init__(self, symbol):\n",
        "    # the board is represented by an n * n array,\n",
        "    #  1 represents the player who moves first,\n",
        "    # -1 represents another player\n",
        "    #  0 represents an empty position\n",
        "    self.board = np.zeros((BOARD_ROW, BOARD_COL))\n",
        "    self.symbol = symbol\n",
        "    self.winner = 0\n",
        "    self.end = None\n",
        "\n",
        "  @property\n",
        "  def hash_value(self):\n",
        "    hash = 0\n",
        "    for x in np.nditer(self.board):\n",
        "      hash = 3*hash + x + 1   # unique hash\n",
        "    return hash\n",
        "\n",
        "  def next(self, action: str):\n",
        "    id = ACTIONS_KEY_MAP[action]\n",
        "    i, j = id // BOARD_COL, id % BOARD_COL\n",
        "    return self.next_by_pos(i, j)\n",
        "\n",
        "  def next_by_pos(self, i: int, j: int):\n",
        "    assert self.board[i, j] == 0\n",
        "    new_state = State(-self.symbol)      # another player turn\n",
        "    new_state.board = np.copy(self.board)\n",
        "    new_state.board[i, j] = self.symbol  # current player choose to play at (i, j) pos\n",
        "    return new_state\n",
        "\n",
        "  @property\n",
        "  def possible_actions(self):\n",
        "    rev_action_map = {id: key for key, id in ACTIONS_KEY_MAP.items()}\n",
        "    actions = []\n",
        "    for i in range(BOARD_ROW):\n",
        "      for j in range(BOARD_COL):\n",
        "        if self.board[i, j] == 0:\n",
        "          actions.append(rev_action_map[BOARD_COL*i+j])\n",
        "    return actions\n",
        "\n",
        "  def is_end(self):\n",
        "    if self.end is not None:\n",
        "      return self.end\n",
        "\n",
        "    check = []\n",
        "    # check row\n",
        "    for i in range(BOARD_ROW):\n",
        "      check.append(sum(self.board[i, :]))\n",
        "\n",
        "    # check col\n",
        "    for i in range(BOARD_COL):\n",
        "      check.append(sum(self.board[:, i]))\n",
        "\n",
        "    # check diagonal\n",
        "    diagonal = 0; reverse_diagonal = 0\n",
        "    for i in range(BOARD_ROW):\n",
        "      diagonal += self.board[i, i]\n",
        "      reverse_diagonal += self.board[BOARD_ROW-i-1, i]\n",
        "    check.append(diagonal)\n",
        "    check.append(reverse_diagonal)\n",
        "\n",
        "    for x in check:\n",
        "      if x == 3:\n",
        "        self.end = True\n",
        "        self.winner = 1   # player 1 wins\n",
        "        return self.end\n",
        "      elif x == -3:\n",
        "        self.end = True\n",
        "        self.winner = 2   # player 2 wins\n",
        "        return self.end\n",
        "\n",
        "    for x in np.nditer(self.board):\n",
        "      if x == 0:          # play available\n",
        "        self.end = False\n",
        "        return self.end\n",
        "\n",
        "    self.winner = 0       # draw\n",
        "    self.end = True\n",
        "    return self.end"
      ],
      "metadata": {
        "id": "IFBWExhtRAMR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Environment"
      ],
      "metadata": {
        "id": "ihwyqTpPy2H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Env:\n",
        "  def __init__(self):\n",
        "    self.all_states = self.get_all_states()\n",
        "    self.curr_state = State(symbol=1)\n",
        "\n",
        "  def get_all_states(self):\n",
        "    all_states = {}  # is a dict with key as state_hash_value and value as State object.\n",
        "    def explore_all_substates(state):\n",
        "      for i in range(BOARD_ROW):\n",
        "        for j in range(BOARD_COL):\n",
        "          if state.board[i, j] == 0:\n",
        "            next_state = state.next_by_pos(i, j)\n",
        "            if next_state.hash_value not in all_states:\n",
        "              all_states[next_state.hash_value] = next_state\n",
        "              if not next_state.is_end():\n",
        "                explore_all_substates(next_state)\n",
        "    curr_state = State(symbol=1)\n",
        "    all_states[curr_state.hash_value] = curr_state\n",
        "    explore_all_substates(curr_state)\n",
        "    return all_states\n",
        "\n",
        "  def reset(self):\n",
        "    self.curr_state = State(symbol=1)\n",
        "    return self.curr_state\n",
        "\n",
        "  def step(self, action):\n",
        "    assert action in self.curr_state.possible_actions, f\"Invalid {action} for the current state \\n{self.curr_state.print_state()}\"\n",
        "    next_state_hash = self.curr_state.next(action).hash_value\n",
        "    next_state = self.all_states[next_state_hash]\n",
        "    self.curr_state = next_state\n",
        "    reward = 0\n",
        "    return self.curr_state, reward\n",
        "\n",
        "  def is_end(self):\n",
        "    return self.curr_state.is_end()\n",
        "\n",
        "  @property\n",
        "  def winner(self):\n",
        "    result_id = self.curr_state.winner\n",
        "    result = 'draw'\n",
        "    if result_id == 1:\n",
        "      result = 'player1'\n",
        "    elif result_id == 2:\n",
        "      result = 'player2'\n",
        "    return result"
      ],
      "metadata": {
        "id": "XJG-IRKIDsz9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Policy"
      ],
      "metadata": {
        "id": "tZKfXapCzHNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasePolicy:\n",
        "  def reset(self):\n",
        "    pass\n",
        "\n",
        "  def update_values(self, *args):\n",
        "    pass\n",
        "\n",
        "  def select_action(self, state):\n",
        "    raise Exception('Not Implemented Error')"
      ],
      "metadata": {
        "id": "pN3u_Ss0lf88"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPolicy(BasePolicy):\n",
        "  def __init__(self, symbol):\n",
        "    self.symbol = symbol\n",
        "\n",
        "  def select_action(self, state):\n",
        "    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n",
        "    print_state(state.board, clear_output=True)\n",
        "    key = input(\"Input your position: \")\n",
        "    return key"
      ],
      "metadata": {
        "id": "OfddswzCRK8p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomPolicy(BasePolicy):\n",
        "  def __init__(self, symbol):\n",
        "    self.symbol = symbol\n",
        "\n",
        "  def select_action(self, state):\n",
        "    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n",
        "    return np.random.choice(state.possible_actions)"
      ],
      "metadata": {
        "id": "kJ_18UpiogzN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActionPlayed(NamedTuple):\n",
        "  hash_value: str\n",
        "  action: str\n",
        "\n",
        "\n",
        "class MenacePolicy(BasePolicy):\n",
        "  def __init__(self, all_states, symbol, tau=5.0):\n",
        "    self.all_states = all_states\n",
        "    self.symbol = symbol\n",
        "    self.tau = tau\n",
        "\n",
        "    # It store the number of stones for each action for each state\n",
        "    self.state_action_value = self.initialize()\n",
        "    # variable to store the history for updating the number of stones\n",
        "    self.history = []\n",
        "\n",
        "  def initialize(self):\n",
        "    state_action_value = {}\n",
        "    for hash_value, state in self.all_states.items():\n",
        "      # initially all actions have 0 stones\n",
        "      state_action_value[hash_value] = {action: 0 for action in state.possible_actions}\n",
        "    return state_action_value\n",
        "\n",
        "  def reset(self):\n",
        "    for action_value in self.state_action_value.values():\n",
        "      for action in action_value.keys():\n",
        "        action_value[action] = 0\n",
        "\n",
        "  def print_updates(self, reward):\n",
        "    print(f'Player with symbol {self.symbol} updates the following history with {reward} stone')\n",
        "    for item in self.history:\n",
        "      board = np.copy(self.all_states[item.hash_value].board)\n",
        "      id = ACTIONS_KEY_MAP[item.action]\n",
        "      i, j = id//BOARD_COL, id%BOARD_COL\n",
        "      board[i, j] = self.symbol\n",
        "      print_state(board)\n",
        "\n",
        "  def update_values(self, reward, show_update=False):\n",
        "    # reward: if wins receive reward of 1 stone for the chosen action\n",
        "    #         else -1 stone.\n",
        "    # reward is either 1 or -1 depending upon if the player has won or lost the game.\n",
        "\n",
        "    if show_update:\n",
        "      self.print_updates(reward)\n",
        "    for item in self.history:\n",
        "\n",
        "      # your code here\n",
        "      self.state_action_value[item.hash_value][item.action] += reward\n",
        "      self.state_action_value[item.hash_value][item.action] = max(0, self.state_action_value[item.hash_value][item.action]) # update state_action with appropriate term.\n",
        "\n",
        "    self.history = []\n",
        "\n",
        "  def select_action(self, state):  # Softmax action probability\n",
        "    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n",
        "    action_value = self.state_action_value[state.hash_value]\n",
        "    max_value = action_value[max(action_value, key=action_value.get)]\n",
        "    exp_values = {action: np.exp((v-max_value) / self.tau) for action, v in action_value.items()}\n",
        "    normalizer = np.sum([v for v in exp_values.values()])\n",
        "    prob = {action: v/normalizer for action, v in exp_values.items()}\n",
        "    action = np.random.choice(list(prob.keys()), p=list(prob.values()))\n",
        "    self.history.append(ActionPlayed(state.hash_value, action))\n",
        "    return action"
      ],
      "metadata": {
        "id": "mos8O8H1RFe5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Game Board"
      ],
      "metadata": {
        "id": "2MvkDRmozqWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Game:\n",
        "  def __init__(self, env, player1, player2):\n",
        "    self.env = env\n",
        "    self.player1 = player1\n",
        "    self.player2 = player2\n",
        "    self.show_updates = False\n",
        "\n",
        "  def alternate(self):\n",
        "    while True:\n",
        "      yield self.player1\n",
        "      yield self.player2\n",
        "\n",
        "  def train(self, epochs=1_00_000):\n",
        "    game_results = []\n",
        "    player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n",
        "    for _ in range(epochs):\n",
        "      result = self.play()\n",
        "\n",
        "      # if player1 wins add 1 stone for the action chosen\n",
        "      player1_reward = player1_reward_map[result]\n",
        "      player2_reward = -player1_reward   # if player2 wins add 1 stone\n",
        "\n",
        "      self.player1.update_values(player1_reward)\n",
        "      self.player2.update_values(player2_reward)\n",
        "\n",
        "  def play(self):\n",
        "    alternate = self.alternate()\n",
        "    state = self.env.reset()\n",
        "    while not self.env.is_end():\n",
        "      player = next(alternate)\n",
        "      action = player.select_action(state)\n",
        "      state, _ = self.env.step(action)\n",
        "    result = self.env.winner\n",
        "    return result"
      ],
      "metadata": {
        "id": "qzO3FQJcCqpJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment"
      ],
      "metadata": {
        "id": "X-gqpWkKztLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = Env()\n",
        "\n",
        "player1 = MenacePolicy(env.all_states, symbol=1)\n",
        "player2 = MenacePolicy(env.all_states, symbol=-1)\n",
        "# player2 = RandomPolicy(symbol=-1)"
      ],
      "metadata": {
        "id": "Pr62H-hLLYdt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game = Game(env, player1, player2)\n",
        "game.train(epochs=1_00_000)"
      ],
      "metadata": {
        "id": "O0d23Pz5SR_y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game_with_human_player = Game(env, player1, HumanPolicy(symbol=-1))\n",
        "\n",
        "game_with_human_player.play()\n",
        "\n",
        "result = env.winner\n",
        "print(f\"winner: {result}\")\n",
        "\n",
        "player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n",
        "player1.update_values(player1_reward_map[result], show_update=True)"
      ],
      "metadata": {
        "id": "qMbqaln6TDXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3aa0abf-a7f3-48db-aafe-94294f0e8c08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "| x | o |   | \n",
            "-------------\n",
            "| o | o | x | \n",
            "-------------\n",
            "| x | x |   | \n",
            "-------------\n",
            "Input your position: c\n",
            "winner: draw\n",
            "Player with symbol 1 updates the following history with 0 stone\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "| o | o | x | \n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x | o |   | \n",
            "-------------\n",
            "| o | o | x | \n",
            "-------------\n",
            "| x | x |   | \n",
            "-------------\n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "| o | o | x | \n",
            "-------------\n",
            "| x | x | o | \n",
            "-------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "game_with_human_player = Game(env, player1, HumanPolicy(symbol=-1))\n",
        "\n",
        "game_with_human_player.play()\n",
        "\n",
        "result = env.winner\n",
        "print(f\"winner: {result}\")\n",
        "\n",
        "player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n",
        "player1.update_values(player1_reward_map[result], show_update=True)"
      ],
      "metadata": {
        "id": "j4Snzpex07LF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aeb0c50-880d-40da-945d-0a4ebbb49f31"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "Input your position: a\n",
            "winner: player1\n",
            "Player with symbol 1 updates the following history with 1 stone\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x |   | x | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "| o | x |   | \n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "game_with_human_player = Game(env, player1, HumanPolicy(symbol=-1))\n",
        "\n",
        "game_with_human_player.play()\n",
        "\n",
        "result = env.winner\n",
        "print(f\"winner: {result}\")\n",
        "\n",
        "player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n",
        "player1.update_values(player1_reward_map[result], show_update=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MwwL84TqD8s",
        "outputId": "ba7ddb76-085b-4bc2-dda1-8ede111ccd54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "| x | x | o | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "Input your position: x\n",
            "winner: draw\n",
            "Player with symbol 1 updates the following history with 0 stone\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x | o |   | \n",
            "-------------\n",
            "|   | x |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x | o |   | \n",
            "-------------\n",
            "|   | x |   | \n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   | x |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   | x | x | \n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "-------------\n",
            "| x | x | o | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "-------------\n",
            "| x | x | o | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "| x | o | o | \n",
            "-------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gxq3vup3qN4h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}